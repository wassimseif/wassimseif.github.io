<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Quantization on Wassim Seifeddine</title><link>https://wassimseifeddine.com/tags/quantization/</link><description>Recent content in Quantization on Wassim Seifeddine</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 25 Dec 2022 17:55:13 +0200</lastBuildDate><atom:link href="https://wassimseifeddine.com/tags/quantization/index.xml" rel="self" type="application/rss+xml"/><item><title>Neural network acceleration</title><link>https://wassimseifeddine.com/posts/nn_acceleration/</link><pubDate>Sun, 25 Dec 2022 17:55:13 +0200</pubDate><guid>https://wassimseifeddine.com/posts/nn_acceleration/</guid><description>&lt;h2 id="why-accelerate"&gt;Why accelerate&lt;/h2&gt;
&lt;p&gt;Well, we have neural networks, they are awesome, they work but there&amp;rsquo;s a problem. THEY ARE &lt;strong&gt;HUGE&lt;/strong&gt;. We scaled from a hundred of millions of parameters to hundred of &lt;strong&gt;BILLIONS&lt;/strong&gt;. This problem makes using neural networks in real life quite hard as you normally don&amp;rsquo;t have this huge computational capabilities to run them anywhere.&lt;/p&gt;
&lt;p&gt;Neural networks have proven to be a very valuable tool in scenarios where the transformation from inputs to outputs is unknown. Suppose you are asked to write an algorithm to classify an image if it&amp;rsquo;s a cat or a dog, how would you do that ? Well first you might ask yourself, &amp;ldquo;what makes an image a cat?&amp;rdquo;. Answering this question is incredibly hard because a vast amount of cases to cover in order to have your algorithm generalizable. This is where neural networks shine; Given an input $ x_{i} $ with its respective label $ y_{i}$ you can use a neural network model with a set of parameters $\theta$ denoted by $ M(\theta) $ to approximate $y_{i} = f(x_{i})$. Normally with enough data you can get a very good estimate of $f$. &lt;strong&gt;However&lt;/strong&gt;, this comes at a huge cost, training and running these large networks is expensive in terms of time and memory because of the huge amount of parameters that you need to learn to get the best approximation, this makes these models hard to use in real life scenarios. Also, the recent trend of models getting bigger and bigger in order to get better performance is making this problem even harder.&lt;/p&gt;</description></item></channel></rss>