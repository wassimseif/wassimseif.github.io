<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>[ARCHIVE] Serving BERT Model with Pytorch using TorchServe - Wassim Seifeddine</title><meta name=Description content="Talking about Machine learning, mostly computational biology, bio foundation models and large scale training"><meta property="og:url" content="https://wassimseifeddine.com/posts/torchserve/"><meta property="og:site_name" content="Wassim Seifeddine"><meta property="og:title" content="[ARCHIVE] Serving BERT Model with Pytorch using TorchServe"><meta property="og:description" content="Finally So finally Pytorch is getting a decent (?) production serving capabilities. TorchServe was introduced a couple of days ago along with other interesting things
I'm not in ANY way expert on putting pytorch in production environment. What I've been using is Flask. I have never tried ONNX or torchscript before to judge on. So TorchServce was announced as a “industrial-grade path to deploying PyTorch models for inference at scale”. In this tutorial we will try to load a finetuned BERT model."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-04-22T23:56:39+00:00"><meta property="article:modified_time" content="2020-04-22T23:56:39+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[ARCHIVE] Serving BERT Model with Pytorch using TorchServe"><meta name=twitter:description content="Finally So finally Pytorch is getting a decent (?) production serving capabilities. TorchServe was introduced a couple of days ago along with other interesting things
I'm not in ANY way expert on putting pytorch in production environment. What I've been using is Flask. I have never tried ONNX or torchscript before to judge on. So TorchServce was announced as a “industrial-grade path to deploying PyTorch models for inference at scale”. In this tutorial we will try to load a finetuned BERT model."><meta name=twitter:site content="@https://twitter.com/WassSeif"><meta name=application-name content="Wassim Seifeddine"><meta name=apple-mobile-web-app-title content="Wassim Seifeddine"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://wassimseifeddine.com/posts/torchserve/><link rel=prev href=https://wassimseifeddine.com/posts/physics_tf/><link rel=next href=https://wassimseifeddine.com/posts/nn_acceleration/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"[ARCHIVE] Serving BERT Model with Pytorch using TorchServe","inLanguage":"en-us","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/wassimseifeddine.com\/posts\/torchserve\/"},"genre":"posts","wordcount":278,"url":"https:\/\/wassimseifeddine.com\/posts\/torchserve\/","datePublished":"2020-04-22T23:56:39+00:00","dateModified":"2020-04-22T23:56:39+00:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Author"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"light"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"light"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Wassim Seifeddine">Wassim Seifeddine</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/about/>About </a><a class=menu-item href=/portfolio/>Portfolio </a><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/conferences/>Conferences </a><a class=menu-item href="https://scholar.google.com/citations?user=x6EK09kAAAAJ&amp;hl=en" rel="noopener noreffer" target=_blank>Publications </a><a class=menu-item href=/seifeddine_wassim_cv.pdf>Resume </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Wassim Seifeddine">Wassim Seifeddine</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/about/ title>About</a><a class=menu-item href=/portfolio/ title>Portfolio</a><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/conferences/ title>Conferences</a><a class=menu-item href="https://scholar.google.com/citations?user=x6EK09kAAAAJ&amp;hl=en" title rel="noopener noreffer" target=_blank>Publications</a><a class=menu-item href=/seifeddine_wassim_cv.pdf title>Resume</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[ARCHIVE] Serving BERT Model with Pytorch using TorchServe</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>Author</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2020-04-22>2020-04-22</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;278 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;2 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#finally>Finally</a><ul><li><a href=#installing-the-requirements>Installing the requirements</a></li><li><a href=#converting-the-model-to-mar-file>Converting the model to MAR file</a></li></ul></li></ul></nav></div></div><div class=content id=content><h2 id=finally>Finally</h2><p>So finally Pytorch is getting a decent (?) production serving capabilities. <a href=https://github.com/pytorch/serve target=_blank rel="noopener noreffer">TorchServe</a> was introduced a <a href=https://medium.com/pytorch/torchserve-and-torchelastic-for-kubernetes-new-pytorch-libraries-for-serving-and-training-models-2efd12e09adc target=_blank rel="noopener noreffer">couple of days ago</a> along with other interesting things</p><div class=tip>I'm not in ANY way expert on putting pytorch in production environment. What I've been using is Flask. I have never tried ONNX or torchscript before to judge on.</div><p>So TorchServce was announced as a &ldquo;industrial-grade path to deploying PyTorch models for inference at scale&rdquo;. In this tutorial we will try to load a finetuned BERT model.</p><h3 id=installing-the-requirements>Installing the requirements</h3><p>2 things you need to get going is the torchserve and torch-model-archiver</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl> pip install torchserve torch-model-archiver
</span></span></code></pre></div><h3 id=converting-the-model-to-mar-file>Converting the model to MAR file</h3><p>Before serving the model, you need to convert it to .mar file, for this step we are going to use the <code>torch-model-archiver</code> we just installed</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/torchserve/torch-model-archiver-help.png data-srcset="/posts/torchserve/torch-model-archiver-help.png, /posts/torchserve/torch-model-archiver-help.png 1.5x, /posts/torchserve/torch-model-archiver-help.png 2x" data-sizes=auto alt=/posts/torchserve/torch-model-archiver-help.png title=/posts/torchserve/torch-model-archiver-help.png width=1898 height=2120></p><p>Some parameter you should pay attention to are</p><ul><li><strong>model-name</strong> : A name you want to specify to the model</li><li><strong>serialized-file</strong>: the model trained weights file</li><li><strong>model-file</strong>: the actual model definition file</li><li><strong>handler</strong>: Will cover it in the next section</li><li><strong>extra-files</strong>: Any extra files you can to add to your serving. will see how it&rsquo;s useful</li></ul><p>A sample command would be something like this</p><pre tabindex=0><code>torch-model-archiver --model-name my-model-name --version 1.0 \
--model-file model.py  --serialized-file ./model.bin \
--extra-files params.py --handler MyCustomHandler.py
</code></pre><p>The <code>--extra-files</code> should include every file that you are using in model.py. In my case they where the hyperparameter of my model</p><div class=tip>Please make sure that you saved the model on the appropriate device. If you trained the model on GPU & trying to serve it on the server without GPU then the next step would fail</div><p>The output of this command would be a single my-model-name.mar file</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-04-22</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://wassimseifeddine.com/posts/torchserve/ data-title="[ARCHIVE] Serving BERT Model with Pytorch using TorchServe" data-via=https://twitter.com/WassSeif><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://wassimseifeddine.com/posts/torchserve/><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://wassimseifeddine.com/posts/torchserve/ data-title="[ARCHIVE] Serving BERT Model with Pytorch using TorchServe"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://wassimseifeddine.com/posts/torchserve/ data-title="[ARCHIVE] Serving BERT Model with Pytorch using TorchServe"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://wassimseifeddine.com/posts/torchserve/ data-title="[ARCHIVE] Serving BERT Model with Pytorch using TorchServe"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/physics_tf/ class=prev rel=prev title="[ARCHIVE] Learning High School Physics with Tensorflow"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>[ARCHIVE] Learning High School Physics with Tensorflow</a>
<a href=/posts/nn_acceleration/ class=next rel=next title="Neural network acceleration">Neural network acceleration<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1}}</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JKG8HGHF8S",{anonymize_ip:!0})</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=G-JKG8HGHF8S" async></script></body></html>