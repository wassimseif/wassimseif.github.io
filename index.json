[{"categories":["AI Research"],"content":"Personal reflections on attending NeurIPS 2025, including insights on mechanistic interpretability and the state of AI research community.","date":"2025-12-08","objectID":"/posts/neurips_2025/","tags":["Mechanistic Interpretability"],"title":"My thoughts on NeurIPS 2025","uri":"/posts/neurips_2025/"},{"categories":["AI Research"],"content":"Coming back from NeurIPS 2025, I thought I’d write some of my thoughts about the conference and the current state of AI research. Given that this was my first time attending the conference (huge mistake for someone who’s working in AI research), I was astonished by the amount of people there, I overheard someone saying that there are around 35,000 people this year, a 60% increase from last year alone. That’s insane (didn’t fact check that) ","date":"2025-12-08","objectID":"/posts/neurips_2025/:0:0","tags":["Mechanistic Interpretability"],"title":"My thoughts on NeurIPS 2025","uri":"/posts/neurips_2025/"},{"categories":["AI Research"],"content":"Thank you First and most importantly, I want to thank the organizers for managing to pull off such a huge event, the logistics behind it must have been a nightmare, and they did an amazing job. The security, catering, cleaning, and admin staff all managed to give us an excellent experience where we can focus only on learning about AI research while everything else is taken care of. Thank you for making this possible. ","date":"2025-12-08","objectID":"/posts/neurips_2025/:1:0","tags":["Mechanistic Interpretability"],"title":"My thoughts on NeurIPS 2025","uri":"/posts/neurips_2025/"},{"categories":["AI Research"],"content":"What I enjoyed While I couldn’t attend many talks (due to scheduling conflicts), I really enjoyed the poster sessions; I tried to attend as much as I could and go through most of the posters. The ability to talk directly to the author(s) and ask them questions about their work is something that I really enjoyed. I tried to ask them how I can use their work with what I currently do and did get some interesting ideas that I will try in the next couple of weeks. Another thing I really enjoyed were the workshops. Even though I only attended a couple of them, I found them very useful; maybe it’s because they’re more focused on a certain topic and they go deeper into it, but I found myself learning a lot more in those workshops than in the main conference talks. ","date":"2025-12-08","objectID":"/posts/neurips_2025/:2:0","tags":["Mechanistic Interpretability"],"title":"My thoughts on NeurIPS 2025","uri":"/posts/neurips_2025/"},{"categories":["AI Research"],"content":"What I didn’t enjoy NeurIPS is not a cheap conference, in fact I think it’s one of the most expensive ones out there; though totally worth it San Diego is not a cheap city to stay in, it’s also one of the most expensive cities in the world. What really annoyed me is the abuse that most hotels did to the attendees. The first hotel I stayed in (shame on you!) was charging 900$ per night for a 12m2 1950s room that has the sink inside the bedroom next to the bed! This extremely high combined cost makes it really hard for students and researchers from low-income countries or labs with limited budget to come and show their work, and this shows in the conference! Having to pay thousands of dollars just to attend the conference isn’t really better than journals asking for subscriptions to give you access to papers, we should work to make science open for all! ","date":"2025-12-08","objectID":"/posts/neurips_2025/:3:0","tags":["Mechanistic Interpretability"],"title":"My thoughts on NeurIPS 2025","uri":"/posts/neurips_2025/"},{"categories":["AI Research"],"content":"What’s the one idea that really stuck with me One topic I wanted to learn about for some time is Mechanistic Interpretability, so when I saw a workshop about it, I immediately signed up for it and it really didn’t disappoint. Dr. Been Kim’s keynote talk about it (Towards a Pareto Frontier of Interpretability: 15 Years of Research in 15 Mins) was eye-opening. I learned a lot about the current state of interpretability research, what works and what doesn’t and the challenges that we still face in this field. During her presentation, she talked about how we can use mech interpretability to extract concepts from models in a certain domain (chess in that case) and use these extracted concepts to teach experts in that domain about new strategies that the model learned but the experts didn’t know about. What really caught my interest is that this might be a way to make a much bigger use of AI without actually waiting for AGI or whatever we’re waiting for. AI (LLMs in this case) are exceptionally good at extracting patterns in data that us as humans miss, so if we use this technique ( and if it works well ) to extract these patterns and teach them to humans that are experts in a certain, we can make a lot of progress in various fields without actually needing to have a super intelligent AI that can do it completely for us. I managed to talk to Dr. Been Kim after her talk and she was kind enough to answer my questions; I wanted to understand what kind of “concepts” these techniques were extracting and whether this can be applied to other data domains (DNA/RNA and Protein LLMs) and she seemed quite positive about it, so that’s something I will experiments with in the next couple of weeks ","date":"2025-12-08","objectID":"/posts/neurips_2025/:4:0","tags":["Mechanistic Interpretability"],"title":"My thoughts on NeurIPS 2025","uri":"/posts/neurips_2025/"},{"categories":["AI Research"],"content":"Final Remarks Even with some downsides ( how expensive it is ), NeurIPS 2025 was an amazing experience, I learned a lot, met a lot of interesting people and got to see some amazing research. If you are working in that domain or interested in joining it, definitely attend it if you can and make the best out of it. Networking is key in this field and NeurIPS is the perfect place to do it. Most of the people there share similar interests so I found it easy to have a good long conversation with them about their work. See you next year NeurIPS! ","date":"2025-12-08","objectID":"/posts/neurips_2025/:5:0","tags":["Mechanistic Interpretability"],"title":"My thoughts on NeurIPS 2025","uri":"/posts/neurips_2025/"},{"categories":["AI Research"],"content":"Analysis of Apple Intelligence delays and reflections on current AI capabilities, LLM limitations, and the potential for another AI winter.","date":"2025-04-06","objectID":"/posts/apple_intelligence/","tags":["LLMs","AI Winter","Transformers","AGI","AI Limitations","Reasoning Models"],"title":"On Apple intelligence, LLM limitations and the next AI winter","uri":"/posts/apple_intelligence/"},{"categories":["AI Research"],"content":"Apple intelligence is a project that has been in the works for a while now, and it has been rumored to be a major feature in iOS 18 and the new iPhone 16. However, the project has faced several delays, and it seems that Apple is struggling to get it right. In this post, I will share my thoughts on the reasons behind these delays and what they mean for the future of Apple intelligence and AI. ","date":"2025-04-06","objectID":"/posts/apple_intelligence/:0:0","tags":["LLMs","AI Winter","Transformers","AGI","AI Limitations","Reasoning Models"],"title":"On Apple intelligence, LLM limitations and the next AI winter","uri":"/posts/apple_intelligence/"},{"categories":["AI Research"],"content":"Disclaimer This is a personal blog, and the opinions expressed here are my own. I am not an Apple employee, and I do not have any insider information about the company or its products. There are not a lot of facts to back my opinions, so take everything with a grain of salt. ","date":"2025-04-06","objectID":"/posts/apple_intelligence/:1:0","tags":["LLMs","AI Winter","Transformers","AGI","AI Limitations","Reasoning Models"],"title":"On Apple intelligence, LLM limitations and the next AI winter","uri":"/posts/apple_intelligence/"},{"categories":["AI Research"],"content":"Is Apple really bad with AI ? From an outsider perspective, yes Apple looks like they are struggling, they promised Apple intelligence which is supposed to do a lot of “contextual” actions using your data but what we currently see implemented so far is not very different than your typical text LLM that can reformat your text, write something on your behalf or some text/image post-processing. So yes, Apple did promise us AI but what we got isn’t far from what we already have. if we stop here, the conclusion is that Apple is lacking behind and other companies will crush them, but let’s think of why is apple struggling. ","date":"2025-04-06","objectID":"/posts/apple_intelligence/:2:0","tags":["LLMs","AI Winter","Transformers","AGI","AI Limitations","Reasoning Models"],"title":"On Apple intelligence, LLM limitations and the next AI winter","uri":"/posts/apple_intelligence/"},{"categories":["AI Research"],"content":"What happened? I don’t think Apple is incapable of building that they promised, in contrast, I think they are the most capable of doing so since they control the hardware/software of the whole ecosystem, so what went wrong? What I believe is that Apple really tried to deliver on their promises but they were kind of shocked by the current state of AI, LLMs and transformers; they thought that they can build a system that can understand context, user intent and do complex tasks on behalf of users but found the technology is not there yet. One indication of this is Apple’s “controversial” paper The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity that talks about how LLM can’t really reason behind a certain threshold of problem complexity ( which Apple Intelligence requires). You can also see other LLMS SaaS companies also struggling with their new releases, every couple of months we get a small benchmark improment on top of the previous one and the promise of AGI gets pushed for the next release, as if we understand what AGI is to have an ETA on it ! To make it simple, I think Apple promised their users a lot more than what the current AI tech can deliver; they didn’t really do all of the due diligence and now they are paying for it. They’re scrambling to get something out the door that brings value to their users and not be very embrassing for them. Let’s see how this plays out in the next couple of months. ","date":"2025-04-06","objectID":"/posts/apple_intelligence/:3:0","tags":["LLMs","AI Winter","Transformers","AGI","AI Limitations","Reasoning Models"],"title":"On Apple intelligence, LLM limitations and the next AI winter","uri":"/posts/apple_intelligence/"},{"categories":["AI Research"],"content":"The promise of AI, Transformers and LLMs There was been a lot of talk about whether the current AI progress is just hype and the tech isn’t really there yet, while I do agree with that current AI capabilities are extremely oversold and hyped, I still believe that there’s merit in the current tech that is not just air and can be used in a helpful way. LLMS are not super intelligence and we don’t have a clear path to make them more intelligent than they already are now. They are just a tool that extracts patterns from data and uses this information in a way that looks intelligent, but they don’t really understand the world or have any real intelligence. Should we just abadon ship and call it a day ? No! LLMs are still useful tools that can be used to build applications that can help people, but we need to be realistic with our expectations. ","date":"2025-04-06","objectID":"/posts/apple_intelligence/:4:0","tags":["LLMs","AI Winter","Transformers","AGI","AI Limitations","Reasoning Models"],"title":"On Apple intelligence, LLM limitations and the next AI winter","uri":"/posts/apple_intelligence/"},{"categories":["AI Research"],"content":"What does this mean for AI; Who’s the culprit Honestly, for someone who works in this field, it’s a little bit scary/exciting, when people realize that LLMs are not really AGI (whatever that is) and they are not capable of doing super human intelligence and that the next model from [ your favorite LLM SaaS] will not be AGI but a small improvemnt on top of what we currently have, people will start losing interest in AI and the whole field will suffer. This is what happened in the previous AI winters, and we might be heading towards something similar. If that evers happens, just remember, it’s not really the tech that’s lacking, it’s all the stuff around it; the overvalued startups, the greedy investors/gamblers, your Linkedin guru who is trying to sell you his n8n course that will bring you millions of dollars in leads, it’s all of the stuff around the tech; but not really the tech. ","date":"2025-04-06","objectID":"/posts/apple_intelligence/:5:0","tags":["LLMs","AI Winter","Transformers","AGI","AI Limitations","Reasoning Models"],"title":"On Apple intelligence, LLM limitations and the next AI winter","uri":"/posts/apple_intelligence/"},{"categories":["Deep Learning","Distributed Training"],"content":"Comprehensive overview of TorchTitan, a PyTorch library that simplifies implementing parallelism techniques for training large language models on hundreds of GPUs.","date":"2024-12-13","objectID":"/posts/torchtitan/","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Torchtitan is an excellent project to learn how to implement distributed training techniques for training massive language models on hundreds of GPUs. I’ve been using it for a few months, and now that the paper is out, I thought it’d be a good idea to share a few posts about how to use it, what works and what doesn’t, what I learned while implementing these ideas in my own project. This post will be an overview of the distributed training techniques implemented in Torchtitan and why they are important. In the next couple of posts, I will be writing about my experience implementing each technique in my own project and what I learned from it and how much it actually helped. ","date":"2024-12-13","objectID":"/posts/torchtitan/:0:0","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"1. Introduction Torchtitan is a project from pytorch’s team, it’s their attempt to consolidate all the parallelism and distributed training techniques available in Pytorch into a single framework that can be used to train large models on hundreds of GPUs and they did an excellent job at it. The techniques implemented in Torchtitan are modular, easy to understand and use, and they are all built on top of mostly vanilla Pytorch. I use it more as a learning tool, to understand how to implement parallelism techniques in Pytorch, and to see how the Pytorch team is thinking about scaling deep learning models. ","date":"2024-12-13","objectID":"/posts/torchtitan/:1:0","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"2. Why is This Important? Torchtitan simplifies a few things that were missing or hard to do correctly in PyTorch: A unified, central resource for all parallelism techniques (implemented by the PyTorch team). Faster experimentation thanks to a clean, modular design. Consolidation or improvement of a few libraries: Pippy -\u003e torch.distributed.pipelining FSDP1 -\u003e FSDP2 FlatParameter -\u003e DTensor ","date":"2024-12-13","objectID":"/posts/torchtitan/:2:0","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"3. Scaling Techniques in Torchtitan Torchtitan’s techniques are very modular. Think of them like building blocks you can add or remove from your sharding strategy. The full pipeline looks like this: Image from the Torchtitan paper This design makes it easier to experiment without too much code refactoring. ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:0","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Meta Initialization This is the simplest technique. It initializes the model on an empty device, so the weights aren’t materialized until you apply the full sharding strategy. Saves a lot of time and memory headaches. ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:1","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Float8 Training I haven’t tested this yet because I don’t have access to H100s. They use the torchao implementation. The claim is that this will give you a huge speedup in training time (on the correct hardware) up to 50% in some cases. I will learn about this in the future and write a post about it when i test it. Table 1 from the paper ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:2","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Pipeline Parallelism This is the first step the “sharding” actualy happens. They divide the model into computation stages, each stage is sent to a device along with the required weights. The stages can also further split vertically ( more pipeline parallelism) or horizontally (tensor parallelism). ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:3","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Tensor Parallelism They leverage the new Distributed Tensor (DTensor) to split a layer’s weight. This was once tricky to do in plain PyTorch. This partitioniing allows sharded computation through PyTorch’s RowwiseParallel and ColwiseParallel APIs without changing the model code a lot. They also use Asynchronous Tensor Parallel to further improve the GPU utilization by minimizing the time a GPU waits for new tensors coming from the communication link (NVLink, ethernet…). ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:4","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"FSDP2 They have improved on FSDP1 by improving the FlatParamter and replacing it by a new implementation called DTensor (Distributed Tensor). This new data type also used in Tensor Parallelism. They have around 7% improvement over FSDP1 which is a nice free improvement to have. They use FSDP in 2 cases : 1D parallelism and CPU offloading. Shard on node level if used with other parallelism techniques. ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:5","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Regional Compilation Instead of rely on Pytorch’s Compiler docs to compile the whole model and hope that it gets it optimized. They compile only specific blocks (TransformerBlock) where the attention is which gives them a simpler graph and since they’re compiling the same structe, they only have to compile it once and save a lot of compilation time. ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:6","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Flight Recorder Comes very handy when you are debugging what nccl is doing. ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:7","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Fault Tolerance Training This is a very interesting feature, it allows your training loop to continue even if. I still have to test it. ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:8","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Wandb Integration Although tensorboard is the default, they finally have some wandb integration ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:9","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"Other Features Asynchronous Tensor Parallel Sequence Parallel (?) Context Parallel (?) Most of these features are controlled by the ParallelDims class implemented here. This lets you represent your model’s sharding strategy intuitively. ","date":"2024-12-13","objectID":"/posts/torchtitan/:3:10","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Deep Learning","Distributed Training"],"content":"3. Next Steps If you are interested in learning more about Torchtitan, I would recommend reading the paper it’s quite detailed and it explains the techniques implemented in the library in detail. Also, checkout the Github repo, In the supplementary materials of the paper you’ll find code sections for a technique implemented so you can use this to understand the repository better. If you're interested in this topic or have any questions, feel free to reach out to me. ","date":"2024-12-13","objectID":"/posts/torchtitan/:4:0","tags":["PyTorch","TorchTitan","Distributed Training","Model Parallelism","FSDP","Pipeline Parallelism","Tensor Parallelism","LLMs"],"title":"Torchtitan: A PyTorch Library for Parallelism Techniques explained","uri":"/posts/torchtitan/"},{"categories":["Bioinformatics","Tutorials"],"content":"Step-by-step guide to installing BLAST on macOS, downloading sequence databases, and running efficient sequence alignment searches.","date":"2024-04-24","objectID":"/posts/blast_p1/","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"BLAST (Basic Local Alignment Search Tool) is a widely used tool for comparing nucleotide or protein sequences against databases. If you’re working on macOS and need to use any of its tools, this guide will help you install BLAST, download necessary databases, and run BLAST searches efficiently. ","date":"2024-04-24","objectID":"/posts/blast_p1/:0:0","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"Installing ","date":"2024-04-24","objectID":"/posts/blast_p1/:1:0","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"Manually Installing BLAST manually gives you control over the installation process and allows you to install the latest version directly from NCBI. Download the BLAST Package: Visit the NCBI BLAST download page: NCBI BLAST+ Download Download the latest macOS binary package For intel based mac typically the file name should be like ncbi-blast-x.xx.x+-x64-macosx.tar.gz. For apple silicone based mac typically the file name should be like ncbi-blast-x.xx.x+-aarch64-macosx.tar.gz . with x.xx.x as the version. As the time of writing this guide the latest version is 2.16.0. cd ~/Downloads curl -O https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.13.0+-x64-macosx.tar.gz Note: Replace the URL with correct one for your platform. Extract the Package: Open Terminal and navigate to the download directory: cd ~/Downloads tar -zxvf ncbi-blast-2.16.0+-x64-macosx.tar.gz You can now use BLAST binaries in the ncbi-blast-2.16.0+/bin directory. cd ncbi-blast-2.16.0+/bin ./blastn -version If everything is working correctly, you should see the BLAST version information. blastn: 2.16.0+ Package: blast 2.16.0, build Jun 25 2024 11:53:51 Making BLAST available anywhere Right now if you want to use BLAST, you have to be in the ncbi-blast-2.16.0+/bin directory. To make it accessible anywhere, there are two solutions. Either move the binaries into where your shell ( terminal ) searches for binaries, or tell it to look somewhere else (where BLAST is installed). I normally prefer the second optione because It gives me more flexibility on where I can install and manage third party tools I can have multiple version of BLAST and switch between them in one command The way to accomplish this is by adding the directory where BLAST is installed to the PATH environment variable in macOS. The PATH variable simply contains a list of directories that macos uses to seacrh for binaries. To add a directory into this variable, simply locate where BLAST is installed, for my setup, I keep such tools in ~/third_party/blast/\u003cversion\u003e/bin so for version 2.16.0, the full directory path would be ~/third_party/blast/2.16.0/bin export PATH=\"$HOME/third_party/blast/2.16.0/bin:$PATH\" Note: This applies only to your current SHELL session, if you open a new terminal, you’ll have to execute this command again to make BLAST accessbile for this session. To make it persistant across sessions, you’ll have to add the command to ~/.bashrc or ~/.zshrc. Verify Installation: blastn -version You should see the BLAST version information. ","date":"2024-04-24","objectID":"/posts/blast_p1/:1:1","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"Via Homebrew Homebrew simplifies software installation on macOS. Install Homebrew (if not already installed): /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Install BLAST via Homebrew: brew install blast Verify Installation: blastn -version ","date":"2024-04-24","objectID":"/posts/blast_p1/:1:2","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"Downloading the Database BLAST requires databases to compare your query sequences against. Their database is available here. Choose a Database: Common databases: nt: Nucleotide collection. It is used for nucleotide sequence searches, so if you have a DNA or RNA sequence and want to find similar nucleotide sequences, you would use the nt database. nr: Non-redundant protein sequences. It is used for protein sequence searches, so if you have a protein sequence and want to find similar proteins, you would use the nr database. Specific organism databases Create a Directory for Databases: mkdir -p ~/blastdb Download Databases Using update_blastdb.pl: You can download the database manually from the link above then extract them. However, BLAST provides a script to automatically do it. The script is called update_blastdb.pl and is included in the ncbi-blast-2.16.0+/bin directory. The update_blastdb.pl script is included with BLAST. Since you made the full bin directory available in your PATH, you can also run this script from anywhere. update_blastdb.pl --decompress nt ~/blastdb # for nt database update_blastdb.pl --decompress nr ~/blastdb # for nr database Note: Replace nt with the database of your choice. The problem is that the database is huge and you probably shouldn’t download all of it in your mac if you have another option. Normally I have a small database locally that I use to test scripts and when i’m confident with the script, I run it on the server where the full database is available. Download a partial database You can download only one part of the database by specifying the part you want to download. For example, to download the first file of the nt or nr database, you can run the following command: update_blastdb.pl --decompress nt.00 ~/blastdb # for nt database or using curl curl -O https://ftp.ncbi.nlm.nih.gov/blast/db/nr.00.tar.gz tar -zxvf nr.00.tar.gz Note: This file is 33GB in size before uncompressing, so make sure you have enough space on your mac. Set the BLASTDB Environment Variable: Like the terminal needs to know where to search for binaries, BLAST needs to know where to search for databases. You can set the BLASTDB environment variable to the directory where you downloaded the databases. export BLASTDB=~/blastdb This also applies only to your current SHELL session, if you open a new terminal, you’ll have to execute this command again to make BLASTDB accessbile to BLAST. To make it persistant across session, you’ll have to add the command to ~/.bashrc or ~/.zshrc. Verify Database Files: ls ~/blastdb ","date":"2024-04-24","objectID":"/posts/blast_p1/:2:0","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"Running BLAST With BLAST installed and databases downloaded, you can perform searches. Prepare Your Query Sequence File: Save your sequence in FASTA format (e.g., query.fasta). You can try the below sequence as a test. \u003eSeq1 ATGGGTAAGGAGGACAAGACTCACCTTAACGT CGTCGTCATCGGCCACGTCGACTCTGGCAAGT CGACCACTGTAAGTACAACCAACAGCGGGTTG CTTATCTGCACTCGGAATCCGCCAAACCTGGC AGGGTATCACCAAAACATCTTGCTAACTTTTG ACAGACCGGTCACTTGATCTACCAGTGCGGTG GTATCGACAAGCGAACCATCGAGAAGTTCGAG AAGGTTAGTCAATATCCCTTCGATTACGCGCG CTCCCATCGATTCCCACGATTCGCTCCCTCAC TCGAAACACATCCATTACCCCGCTCGAGTCCG AAAATTTTGCGGTGCGACCGTGATTTTTTCTG GTGGGGTATCTTACCCCGCCACTCGAGTCACG GATGCGCTTGCCCTGTTCCCACAAAACCTTAC CACCCTGTCGCGCACTACATGTCTTGCAGTCA CTAACCACTGGACAATAGGAAGCCGCCGAGCT CGGAAAGGGTTCCTTCAAGTACGCCTGGGTTC TTGACAAGCTCAAAGCCGAGCGTGAGCGTGGT ATCACCATTGATATCGCTCTCTGGAAGTTCGA GACTCCTCGCTACTATGTCACCGTCATTGGTA TGTTGTCACCGTCTCACACTATCATGTATTCA TCATGCTAACATCTCTCTCAGATGCCCCCGGT CATCGTGATTTCATCAAGAACATGATC Run a BLAST Search: blastn -query query.fasta -db nt -out results.txt blastn: Nucleotide-nucleotide BLAST -query: Input file -db: Database name -out: Output file Customize Search Parameters (Optional): blastn -query query.fasta -db nt -out results.txt -evalue 1e-5 -outfmt 6 -max_target_seqs 10 -evalue: Expectation value threshold -outfmt 6: Tabular output format -max_target_seqs: Maximum number of aligned sequences to keep Note: if you are getting any error related to the database, make sure that: BLASTDB environment variable is set correctly. The database is downloaded and decompressed correctly. The database is in the correct directory. You can run blastdbcmd -db nt -info to check if the database is correctly installed. Make sure you are using the correct database name in the command. Make sure you are using the correct command. blastn for nucleotide-nucleotide BLAST blastp for protein-protein BLAST View Results: less results.txt ","date":"2024-04-24","objectID":"/posts/blast_p1/:3:0","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"Conclusion Installing BLAST on macOS is straightforward, whether you choose a manual installation or use Homebrew. With BLAST set up and databases downloaded, you’re ready to perform powerful sequence analyses directly from your Mac. In the next guide, I’ll go over how to interpret the results from BLAST. ","date":"2024-04-24","objectID":"/posts/blast_p1/:4:0","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":["Bioinformatics","Tutorials"],"content":"References NCBI BLAST+ Download BLAST Command Line Applications User Manual Homebrew NCBI BLAST Databases ","date":"2024-04-24","objectID":"/posts/blast_p1/:5:0","tags":["BLAST","Bioinformatics","Computational Biology","Sequence Analysis"],"title":"How to install BLAST on mac and download the database","uri":"/posts/blast_p1/"},{"categories":null,"content":"In this blog I will share my thoughts on machine learning, although some other topics might pop up. I will try to be as concise as possible and avoid all the unnecessary jargon *cough* academia *cough*. I hope you not only enjoy the content but also learn something new. Disclaimers: I am not an expert on all of the topics I will be discussing. I am just a person trying to learn and share my thoughts. Posts are always WIP, I will try to keep them up to date but I might miss some things. There will be mistakes in the posts. I will fix them as soon as I notice them, If you notice any mistakes please let me know by email. If you have ideas of topics, please share them with me. I’m always keen to learn new things :) ","date":"2022-12-25","objectID":"/posts/intro/:0:0","tags":null,"title":"Intro","uri":"/posts/intro/"},{"categories":["Deep Learning"],"content":"Exploration of neural network acceleration techniques including quantization, pruning, and other methods to reduce model size and improve performance.","date":"2022-12-25","objectID":"/posts/nn_acceleration/","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"Why accelerate Well, we have neural networks, they are awesome, they work but there’s a problem. THEY ARE HUGE. We scaled from a hundred of millions of parameters to hundred of BILLIONS. This problem makes using neural networks in real life quite hard as you normally don’t have this huge computational capabilities to run them anywhere. Neural networks have proven to be a very valuable tool in scenarios where the transformation from inputs to outputs is unknown. Suppose you are asked to write an algorithm to classify an image if it’s a cat or a dog, how would you do that ? Well first you might ask yourself, “what makes an image a cat?”. Answering this question is incredibly hard because a vast amount of cases to cover in order to have your algorithm generalizable. This is where neural networks shine; Given an input $ x_{i} $ with its respective label $ y_{i}$ you can use a neural network model with a set of parameters $\\theta$ denoted by $ M(\\theta) $ to approximate $y_{i} = f(x_{i})$. Normally with enough data you can get a very good estimate of $f$. However, this comes at a huge cost, training and running these large networks is expensive in terms of time and memory because of the huge amount of parameters that you need to learn to get the best approximation, this makes these models hard to use in real life scenarios. Also, the recent trend of models getting bigger and bigger in order to get better performance is making this problem even harder. Model size for language models There has been a lot of effort in trying to accelerate these models. Let’s talk more about this. ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:1:0","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"Accelerating Training vs Inference It’s important to note something. Accelerating neural networks comes in two forms. Accelerating training and/or accelerating inference. ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:2:0","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"Training Accelerating training is the process of speeding up the learning of the parameters of the neural network. This is normally more tricky to get right than accelerating inference. ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:2:1","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"Inference Accelerating inference is the process of speeding up the running of a neural network. Normally the process is that you take a trained slow model, and then you try to make it run faster while preserving the same performance. Both techniques are very helpful because they bring us closer to using these model in real life applications, however, it’s more interesting to look at the acceleration of the training of the neural network or the combination of both. ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:2:2","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"Techniques There are a lot of techniques to accelerate neural networks. I can only discuss quantization as this is the one I’m most familiar with. I will try to cover the other techniques in future edits. Some of the techniques are: Layer/Weight Pruning. Quantization. Knowledge Distillation. Parameter Sharing. Tensor decomposition. ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:3:0","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"Quantization ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:4:0","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"Description: Quantization1 is an very interesting field of model compression it’s personally my favorite and the one I’m most experienced in so I’ll discuss it the most. To undertand quantization we need to understand the concept of numbers on a computer. What are numbers: For us number are just a set of symbols that we use to represent a value. We see and treat numbers in the decimal system (base 10) but there are other systems like binary (base 2) or hexadecimal (base 16). For computers numbers are represented in binary (base 2) which has only 1’s and 0’s. There has to be some standardization on how numbers are represented because it might become very messy and we can’t share computations across systems. This is where the IEEE 754 standard comes in. This standard defines how numbers are represented in binary the most common representation is the floating point representation on 32 bits denoted by fp32 or single precision. This representations reserves 32-bits for every number and is composed of 3 parts: Sign bit $s$: 1 bit that represents the sign of the number. Mantissa $m$: 23 bits that represent the value of the number. Exponent $e$: 8 bits that represent the exponent of the number. The value of the number is calculated roughly as: $(-1)^{sign} \\times 2^{e -127} \\times (1 + m)$. This is a very simplified explanation of how numbers are represented in computers. Discussion on how operations are done in this representation and the problems with it is out of the scope of this blog post. The important part is what is mentioned above: This representations reserves 32-bits for every number. Reserves 32-bits for every number. 32-bits for every number. 32-bits. In case you still didn’t get it, this means that every number is represented by 32-bits. This is a lot of space for a number. The most important question is: Do we need that ?. To answer this question, we need to understand what need means. To be continued… December 25 2022: It’s christmas so i’ll stop here and continue after the holidays. ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:4:1","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"How to do it: ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:4:2","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":["Deep Learning"],"content":"References https://arxiv.org/abs/2103.13630 ↩︎ ","date":"2022-12-25","objectID":"/posts/nn_acceleration/:5:0","tags":["Quantization","Pruning"],"title":"Neural network acceleration","uri":"/posts/nn_acceleration/"},{"categories":null,"content":"Portfolio","date":"2021-07-23","objectID":"/conferences/","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"Below is the list of conferences that I attended during my research and industry work Conferences ","date":"2021-07-23","objectID":"/conferences/:0:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"Live Panel Discussion: AI in Healthcare: Opportunities, Challenges, and Ethical Dimensions Description: Panel discussion organized by Toptal. It aims to delve into the significant impact of AI in healthcare, covering real-world applications, ethical considerations, and the future of healthcare innovation through expert insights and interactive Q\u0026A sessions​. Link: Link Place: Online Date: December 2023 What I did: One of the panelist talking about DNA/RNA seqeuencing technologies in AI and discussing the etthical implications of AI in Healthcare ","date":"2021-07-23","objectID":"/conferences/:1:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"Slush 2023 Description: Slush is a startup and tech event held annually in Helsinki, Finland. Slush facilitates meetings between the founders of startups and investors such as venture capitalists, accomplished with events such as matchmaking and pitching competitions. Link: Link Place: Helsinki, Finland Date: November 2023 What I did: Participated in a panel discussion about AI adoption in the startup world with Adrián González Sánchez and Jaime De Mora ","date":"2021-07-23","objectID":"/conferences/:2:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"Toptal Global Developer Conference Description: Developer focused conference to present and discuss latest improvements in new and excitings topics in AI, ML, BigData, DevOps … Link: Link Place: Online Date: October 2023 What I did: Presented a talk about introduction to machine learning from a non-technical point of view Presentation: Link Video Presentation: Watch here ","date":"2021-07-23","objectID":"/conferences/:3:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"Big Data \u0026 AI Day Paris Description: Showcased as an Artificial Intelligence specialist at the Toptal pavilion, I engaged in insightful dialogues about AI/ML initiatives with professionals keen on integrating such advancements into their enterprises. Link: Link Place: France, Paris Date: September 2023 What I did: Discussion with industry leaders and keep entrepenuers to talk about ways to integrate AI into their businesses ","date":"2021-07-23","objectID":"/conferences/:4:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"Lean AI Workshop Description: A more casual workshop to present and discuss work being done on this project ( including my thesis). This should have the most general overview of my work during the PhD Link: N/A Place: France, Paris Date: July 2022 What I did: Presented my work during the PhD so far Presentation: Link ","date":"2021-07-23","objectID":"/conferences/:5:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"GDR IM (Informatique Mathématique) 2022 Description (FR): Les journées JNIM (Journées Nationales de l’Informatique Mathématique) sont organisées chaque année par le GDR IM (Informatique Mathématique). C’est un lieu d’information et d’échange annuel entre chercheurs de la discipline et, tout particulièrement, entre chercheurs du GDR. Link: https://webtv.univ-lille.fr/grp/601/jnim-2022-journees-nationales-du-gdr-im/ Place: France, Lile Date: March 2022 What I did: Presented my poster on custom neural network quantization Poster: Link ","date":"2021-07-23","objectID":"/conferences/:6:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"PEMWN 2021 Description: The 10Th IFIP/IEEE International Conference On Performance Evaluation And Modeling In Wired And Wireless Network Link: https://sites.google.com/view/pemwn2021/program Place: Online Date: November 2021 What I did: Presented my paper on Neural Network Offloading Presentation: Link Video Presentation: Watch here ","date":"2021-07-23","objectID":"/conferences/:7:0","tags":null,"title":"Portfolio","uri":"/conferences/"},{"categories":null,"content":"Portfolio","date":"2021-07-23","objectID":"/portfolio/","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Update This is very outdated. For my most updated portfolio, please visit my profile here Portfolio Below is the list of projects I worked on. I believe that your work is as good as you can show it, that’s why I try to put each project in a demo-able format. For now I am using streamlit as a tool to demo the models i build. ","date":"2021-07-23","objectID":"/portfolio/:0:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Language Modeling for multiple languages ","date":"2021-07-23","objectID":"/portfolio/:1:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Description I refined a Large Language Model by fine-tuning it on a customized dataset. Also I implemented a seamless pipeline for deployment on the Bittensor networ to achieve the lowest loss. One of the models is trained on the The Mountain dataset with 20B parameters. The training was made possible with the help of DeepSpeed on an 8x A100 GPU machine. ","date":"2021-07-23","objectID":"/portfolio/:2:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Tech Stack GPT-(2.7,6B,20B) from EleutherAI Huggingface for finetuning feature The Mountain as a dataset Bittensor for deployment Twitter Sentiment Analysis DEMO ","date":"2021-07-23","objectID":"/portfolio/:3:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Description This is the simple model where you can analyze the sentiment of a single tweet by writing it in a text box, or you can also analyze a sentiment of hashtag. The approach I used is utilizing transfer learning to fine-tune an existing Transformer based model ( specifically the distilbert-base-uncased). I fine-tuned the model on the Sentiment140 dataset. ","date":"2021-07-23","objectID":"/portfolio/:4:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Tech Stack Flair for NLP finetuning and data preprocessing. Huggingface for using the pipeline feature Tweepy for fetching the tweets from the twitter. Streamlit for building the demo app. Quantized Neural Network for Object Detection ","date":"2021-07-23","objectID":"/portfolio/:5:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Description This work was done as part of a project with a self driving car company. The aim was to take a pre-trained model and try to run it as fast as possible and as light as possible to be used for real-time object detection The model we used is a MobileNetV2 pre-trained model on ImageNet with SSDLite object detector. The model was trained with Fp-32 data format. We applied several model compression techniques to reduce the size of the model and monitor it’s performance. Some of the techniques we used are: Quantization Pruning Fused Convolution Knowledge Distillation We got interesting results with the model. The model can reliably detect objects in images with same accuracy as the Fp-32 version while going as low as Int-8 data format. Disclaimer: This work is not entirely my own. I was part of a team that worked on it. ","date":"2021-07-23","objectID":"/portfolio/:6:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Tech Stack PyTorch for building the model. Tensorboard for monitoring the model. OpenCV for image processing. Legal case classification ","date":"2021-07-23","objectID":"/portfolio/:7:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Description This project was two folds, first we had to build a model that would classify a legal case based on the description entered into several categories. The aim was to provide a tool that will help lawyers to classify the cases faster and easier. Second, we had to extract the entities from the case description that were relevant to the classification. Here’s a small sketch of how the system should behave. Defamation Classification with element extraction This project was extremely interesting as we faced several technical challenges that I never encountered before. Some of the challenges: The data we got was very messy. It was a digitized version of PDF documents Each case in our training data was several hundred words long which made it difficult that we used some NLP models. ","date":"2021-07-23","objectID":"/portfolio/:8:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Tech Stack Doc2Vec for building the baseline model. PyTorch for building the model. Huggingface for using the text tools it provides Weights \u0026 Biases for monitoring the model training. Jupyter Notebooks for showcasing the results of the EDA ","date":"2021-07-23","objectID":"/portfolio/:9:0","tags":null,"title":"Portfolio","uri":"/portfolio/"},{"categories":null,"content":"Services","date":"2021-07-23","objectID":"/services/","tags":null,"title":"Services","uri":"/services/"},{"categories":null,"content":"ChatGPT as a Service I can provide your business with your own ChatGPT model, trained on your own custom dataset that it’s tailored to your business needs. You can have your own Chatbot that can answer your customers questions, help your employees with their daily tasks, increase the productivity of your HR Team and much more, all without worrying about maintaining or training the model. You can reach out to me here ","date":"2021-07-23","objectID":"/services/:1:0","tags":null,"title":"Services","uri":"/services/"},{"categories":null,"content":"ChatGPT Plugin Developer If you want to build a powerful conversational tool built on top of ChatGPT but uses your own knowledge base, I can help with that ! You can reach out to me here ## General Machine Learning Consulting As a machine learning consultant with a focus on natural language processing (NLP) and language modeling, I have spent years building expertise in designing and implementing machine learning algorithms and models that can analyze and understand the complexities of human language. I have worked with clients from various industries and have helped them extract meaningful insights from large volumes of unstructured text data, automate customer support, and build predictive models for various use cases. My goal is to help organizations harness the power of NLP and language modeling to improve decision-making, enhance customer experiences, and optimize business operations. With a deep understanding of the latest research and best practices in this field, I am well-equipped to guide organizations towards successful implementation and deployment of NLP and language modeling solutions. You can reach out to me here ","date":"2021-07-23","objectID":"/services/:2:0","tags":null,"title":"Services","uri":"/services/"},{"categories":["MLOps"],"content":"Guide to serving BERT models in production using PyTorch TorchServe, covering model archiving and deployment setup.","date":"2020-04-22","objectID":"/posts/torchserve/","tags":["TorchServe","PyTorch","Model Serving","Production ML","Deployment"],"title":"[ARCHIVE] Serving BERT Model with Pytorch using TorchServe","uri":"/posts/torchserve/"},{"categories":["MLOps"],"content":"Finally So finally Pytorch is getting a decent (?) production serving capabilities. TorchServe was introduced a couple of days ago along with other interesting things I'm not in ANY way expert on putting pytorch in production environment. What I've been using is Flask. I have never tried ONNX or torchscript before to judge on. So TorchServce was announced as a “industrial-grade path to deploying PyTorch models for inference at scale”. In this tutorial we will try to load a finetuned BERT model. ","date":"2020-04-22","objectID":"/posts/torchserve/:1:0","tags":["TorchServe","PyTorch","Model Serving","Production ML","Deployment"],"title":"[ARCHIVE] Serving BERT Model with Pytorch using TorchServe","uri":"/posts/torchserve/"},{"categories":["MLOps"],"content":"Installing the requirements 2 things you need to get going is the torchserve and torch-model-archiver pip install torchserve torch-model-archiver ","date":"2020-04-22","objectID":"/posts/torchserve/:1:1","tags":["TorchServe","PyTorch","Model Serving","Production ML","Deployment"],"title":"[ARCHIVE] Serving BERT Model with Pytorch using TorchServe","uri":"/posts/torchserve/"},{"categories":["MLOps"],"content":"Converting the model to MAR file Before serving the model, you need to convert it to .mar file, for this step we are going to use the torch-model-archiver we just installed Some parameter you should pay attention to are model-name : A name you want to specify to the model serialized-file: the model trained weights file model-file: the actual model definition file handler: Will cover it in the next section extra-files: Any extra files you can to add to your serving. will see how it’s useful A sample command would be something like this torch-model-archiver --model-name my-model-name --version 1.0 \\ --model-file model.py --serialized-file ./model.bin \\ --extra-files params.py --handler MyCustomHandler.py The --extra-files should include every file that you are using in model.py. In my case they where the hyperparameter of my model Please make sure that you saved the model on the appropriate device. If you trained the model on GPU \u0026 trying to serve it on the server without GPU then the next step would fail The output of this command would be a single my-model-name.mar file ","date":"2020-04-22","objectID":"/posts/torchserve/:1:2","tags":["TorchServe","PyTorch","Model Serving","Production ML","Deployment"],"title":"[ARCHIVE] Serving BERT Model with Pytorch using TorchServe","uri":"/posts/torchserve/"},{"categories":null,"content":" ## Introduction Learning to convert from Angular displacement to linear displacement was nothing fancy in highschool, but TEACHING a machine learning model how to do the translation is on a whole new level . Just kidding, it's also nothing fancy. ","date":"2018-05-28","objectID":"/posts/physics_tf/:0:0","tags":null,"title":"[ARCHIVE] Learning High School Physics with Tensorflow","uri":"/posts/physics_tf/"},{"categories":null,"content":"Task What we want to do is learn the mapping between the angular rotation (complete circle) of a circular object given its diameter to the distance covered on a linear path So we want to find the length of the underlying line that the circle covers while completing a full rotation. ","date":"2018-05-28","objectID":"/posts/physics_tf/:1:0","tags":null,"title":"[ARCHIVE] Learning High School Physics with Tensorflow","uri":"/posts/physics_tf/"},{"categories":null,"content":"What we already know From highschool, we already know the formula to calculate this function. $y = 2 \\times \\Pi \\times r$ which yields to $y = 6.283185 \\times r$ So we want our Neural network to learn the parameter a = 6.283185 ","date":"2018-05-28","objectID":"/posts/physics_tf/:2:0","tags":null,"title":"[ARCHIVE] Learning High School Physics with Tensorflow","uri":"/posts/physics_tf/"},{"categories":null,"content":"Dataset Since we already have the mapping from input to output, then we can generate the dataset ourselves. import numpy as np import math dataset_size = 200 def generate_dataset(): radii = np.random.uniform(-20, 20, size=dataset_size) np.random.shuffle(radii) distance_covered_by_one_lap = 2.0 * math.pi * radii return radii , distance_covered_by_one_lap We are going to consider the distance covered by 1 full rotation of circles with different radii Since the function is linear, then the curve will be a straight line. ","date":"2018-05-28","objectID":"/posts/physics_tf/:3:0","tags":null,"title":"[ARCHIVE] Learning High School Physics with Tensorflow","uri":"/posts/physics_tf/"},{"categories":null,"content":"Model We are going to use a very simple neural network. Actually it’s not going to be a network, just 1 neuron. ","date":"2018-05-28","objectID":"/posts/physics_tf/:4:0","tags":null,"title":"[ARCHIVE] Learning High School Physics with Tensorflow","uri":"/posts/physics_tf/"},{"categories":null,"content":"Code X = tf.placeholder(dtype=tf.float32,shape=(dataset_size,),name = 'Input_X') Y = tf.placeholder(dtype=tf.float32,shape=(dataset_size,),name = 'Y') def step(X, weight): h = tf.multiply(X,weight) a = tf.nn.relu(h) return a yhat = step(X,w) cost = tf.reduce_sum(tf.pow(tf.subtract(yhat,Y), 2))/(dataset_size) train = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost) init = tf.global_variables_initializer() with tf.Session() as sess : sess.run(init) print(w.eval()) for i in range(100): sess.run(train,feed_dict = { X : radii, Y : distance }) print(w.eval()) While training, after just a few iterations, we will see that the network converged and the scalar w we are training is about 6.2831855 which is the desired value ","date":"2018-05-28","objectID":"/posts/physics_tf/:5:0","tags":null,"title":"[ARCHIVE] Learning High School Physics with Tensorflow","uri":"/posts/physics_tf/"},{"categories":["Deep Learning","Tutorials"],"content":"Tutorial on using TensorFlow's gradient descent optimizer to minimize mathematical functions, demonstrating fundamental ML optimization concepts.","date":"2016-10-02","objectID":"/posts/sgd/","tags":["TensorFlow"],"title":"[ARCHIVE] Using Tensorflow Gradient Descent to minimize functions","uri":"/posts/sgd/"},{"categories":["Deep Learning","Tutorials"],"content":"You probably heard the hype around Gradient Descent \u0026 how it’s used to optimize Deep Learning Models. But you may never knew that it can be used to minimize ANY function you know. In this blog post we’re going to see how to use Gradient Descent to optimize a simple quadratic function we all know from highschool. $ax^2 + bx + c$ with a = 1 b = -40 c = 400 we get the following formula $x^2 - 40x + 400$ which can be written as $(x - 20)^2$ Plotting this function will give us this curve: . From the above figure, we can see that this function achieves minimum at x = 20. since $(20 - 20)^2 = 0$ But suppose this function is a high dimensional function that we can’t simply figure out the minimum, these kind of problems requires some algorithm to find (at least try) to achieve this minimum. Here comes gradient descent! ","date":"2016-10-02","objectID":"/posts/sgd/:0:0","tags":["TensorFlow"],"title":"[ARCHIVE] Using Tensorflow Gradient Descent to minimize functions","uri":"/posts/sgd/"},{"categories":["Deep Learning","Tutorials"],"content":"Gradient Descent What Gradient Descent does is the following: Start at a random value. Calculates the derivative ( slope ) of the function at this point. Descent in the opposite direction. Repeat 1-\u003e3 until convergence ( slope ~ 0 ) Suppose the formula $(x - 20)^2$ is our cost function in a machine learning problem that we’re trying to minimize. Implementation We start by importing the needed libraries, which are numpy \u0026 tensorflow import numpy as np import tensorflow as tf then we start tensorflow Interactive Session. sess = tf.InteractiveSession() We are trying to find a value for the parameters X that will minimize the cost function, so let’s declare this parameter and initialize it to 0 X = tf.Variable([0],dtype= tf.float32) The function we are trying to minimize is Y written as $Y = X^2 - 40X + 400$ So let’s write it too Y = (X**2) - 40*X + 400 We are going to use Tensorflow’s implementation of Gradient Descent with a learning rate of 0.01 Learning Rate: We are not going to discuss it here, but think about it as the magnitude of our optimization. How steep is the optimizer going to descent down to the minimum at each iteration. train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(Y) In Tensorflow, variables are not initialized unless you explicitly do that init = tf.global_variables_initializer() sess.run(init) Now for the training part, we’re going to run the optimizer 1000 times to try to get to our minimum number_of_iterations = 1000 for i in range(number_of_iterations): sess.run(train) Finally after our training is complete, let’s see what the optimizer found a value for X to minimize Y print(X.eval()) we get 19.99995422 which is approximately 20! ","date":"2016-10-02","objectID":"/posts/sgd/:0:1","tags":["TensorFlow"],"title":"[ARCHIVE] Using Tensorflow Gradient Descent to minimize functions","uri":"/posts/sgd/"},{"categories":null,"content":"About Me","date":"2012-07-23","objectID":"/about/","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"Hi my name is Wassim Seifeddine, I am currently working on foundation biology models; trying to understand the basic building blocks of life through AI. I have been working in AI for the past 7 years, with a focus on deep learning and its applications. Previously, I was a PhD student at University of Nantes working on neural network acceleration from the arithmetic standpoint. Before that I did my masters thesis at INRIA under the supervision of Dr. Cedric Adjih and Dr. Nadjib Achir on the topic of AI on the edge. You can find my thesis here ","date":"2012-07-23","objectID":"/about/:0:0","tags":null,"title":"About Me","uri":"/about/"}]